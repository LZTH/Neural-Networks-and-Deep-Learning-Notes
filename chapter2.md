#  反向传播算法


---

上一章对神经网络有了基本认识，在参数(权重和偏置)学习过程中我们知道要使用梯度下降算法。然而，计算梯度可并不简单。这一章介绍反向传播算法——用于快速计算梯度。


![](https://ooo.0o0.ooo/2015/11/10/5641ec00a6aff.png)

通过上式可以发现，计算梯度实际上就是计算偏导数:$$\partial C / \partial w$$, $$\partial C / \partial b$$。



## 一种基于矩阵的算法计算神经网络的输出

在学习反向传播算法之前，先介绍一种基于矩阵的算法来计算NN的输出。

几个要用到的数学符合：$$w_{jk}^{l} $$表示


恶魔有一天变好了，为神经网络所用，虽然还是干着它的老本行：给$$z_{j}^{l}$$加$$\Delta z_{j}^{l}$$, 但现在加$$\Delta z_{j}^{l}$$的目的是调节最后的输出，使得损失函数值减小。举个例子，$$\partial C/ \partial z_{j}^{l}$$绝对值很大(比如 +100000, -9999999)，可以选择


BP -> BPTT-> Hes(Hinton)